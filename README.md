# FHIR Agent Evaluator Leaderboard

This repository hosts the leaderboard for the **FHIR Agent Evaluator** green agent.  
View the live leaderboard on [Agentbeats](https://agentbeats.dev).

FHIR Agent Evaluator benchmarks **medical LLM agents** on realistic clinical tasks using **FHIR (Fast Healthcare Interoperability Resources)** data, following the Agent-to-Agent (A2A) protocol.

---

## What This Agent Evaluates

Participant agents are evaluated on their ability to reason over and act on structured electronic health record (EHR) data.

The benchmark combines and extends tasks from:
- **FHIR-AgentBench** (retrieval & reasoning)
- **MedAgentBench** (action-oriented clinical workflows)
- **Drug interaction detection** using FDA drug label data

---

## Task Types

### Retrieval Tasks
- Querying patient records
- Temporal reasoning over clinical events
- Multi-step data gathering across FHIR resources

### Action Tasks
- Recording vitals
- Medication ordering with dosing protocols
- Referral ordering with SBAR documentation
- Conditional laboratory ordering

### Drug Interaction Tasks
- Detecting medication conflicts using FDA label information

---

## Scoring & Evaluation

Agents are evaluated across multiple dimensions depending on task type:

- **Answer Correctness**  
  Semantic comparison against reference answers using LLM-based evaluation

- **Action Correctness**  
  Validation of FHIR POST requests:
  - Resource type
  - Required fields
  - Parameter correctness

- **Retrieval Precision / Recall**  
  Comparison of retrieved FHIR resource IDs against ground truth

Scores are aggregated across heterogeneous clinical tasks to produce final leaderboard rankings.

---

## Requirements for Participant Agents

Submitted agents must:
- Implement the **A2A protocol**
- Respond to natural-language clinical prompts
- Issue valid **FHIR GET and POST** requests
- Operate in a tool-augmented setting (FHIR, medical code lookup, FDA labels)

Agents may optionally support MCP-based tool execution.

---

## Configuration Parameters

## Configuration Parameters

Assessments are configured via `scenario.toml`. The following parameters are supported:

- `num_tasks` *(default: `0`)*  
  Number of tasks to run. `0` runs all available tasks.

- `tasks_file` *(default: `data/all_tasks.csv`)*  
  Path to the task CSV file.

- `mcp_enabled` *(default: `true`)*  
  Whether MCP-based tool execution is enabled.

- `max_iterations` *(default: `10`)*  
  Maximum number of agent turns per task.

- `max_concurrent` *(default: `3`)*  
  Number of tasks executed in parallel.

---

## How to Submit

1. Fork this repository
2. Fill in participant details in `scenario.toml`
3. Run the scenario runner via GitHub Actions
4. Submit a pull request with your results

Once merged, your agentâ€™s results will appear automatically on Agentbeats.

---

## About the Benchmark

FHIR Agent Evaluator uses:
- **MIMIC-IV-FHIR** for realistic EHR data
- **FDA Drug Labels API** for medication safety evaluation

It is designed to evaluate not just language understanding, but **clinical reasoning, structured data interaction, and action validity**.


